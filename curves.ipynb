{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f64caa2a",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cc20254a",
   "metadata": {},
   "source": [
    "## 1. Carregamento dos Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62f8d8c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Carregar o dataset (certifique-se de que o arquivo 'titanic.csv' esteja na mesma pasta do notebook)\n",
    "df = pd.read_csv('titanic.csv')\n",
    "\n",
    "# Visualizar as 5 primeiras linhas do dataset\n",
    "print(df.head())\n",
    "\n",
    "# Exibir informações gerais do dataset\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51b7fae8",
   "metadata": {},
   "source": [
    "## 2. Tratamento e Preparação das Variáveis\n",
    "\n",
    "Nesta etapa, realizamos o tratamento de valores ausentes, conversão de variáveis categóricas e criação de novas features.\n",
    "\n",
    "**Variáveis importantes (tradução):**\n",
    "- PassengerId: ID do Passageiro\n",
    "- Survived: Sobreviveu\n",
    "- Pclass: Classe\n",
    "- Name: Nome\n",
    "- Sex: Sexo\n",
    "- Age: Idade\n",
    "- SibSp: Nº de Irmãos/Espos\n",
    "- Parch: Nº de Pais/Filhos\n",
    "- Fare: Tarifa\n",
    "- Embarked: Ponto de Embarque"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8180a7b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificar a quantidade de valores ausentes em cada coluna\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Preencher valores ausentes na coluna 'Age' com a mediana\n",
    "df['Age'].fillna(df['Age'].median(), inplace=True)\n",
    "\n",
    "# Preencher 'Embarked' com a moda (valor que mais aparece)\n",
    "df['Embarked'].fillna(df['Embarked'].mode()[0], inplace=True)\n",
    "\n",
    "# Verificar novamente os valores ausentes\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f449ec4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converter a variável 'Sex' para numérico: male -> 0, female -> 1\n",
    "df['Sex'] = df['Sex'].map({'male': 0, 'female': 1})\n",
    "\n",
    "# Verificar as primeiras linhas para confirmar a conversão\n",
    "print(df[['Sex']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57145a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criar a feature 'FamilySize' (Tamanho da Família)\n",
    "df['FamilySize'] = df['SibSp'] + df['Parch'] + 1\n",
    "\n",
    "# Visualizar a nova feature\n",
    "print(df[['SibSp', 'Parch', 'FamilySize']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ee52311",
   "metadata": {},
   "source": [
    "## 3. Divisão dos Dados\n",
    "\n",
    "Dividimos o dataset em conjuntos de treinamento e teste para avaliar a capacidade de generalização do modelo. Selecionaremos algumas features relevantes e a variável alvo (Sobreviveu)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b728dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Selecionar as features: Classe, Sexo, Idade, Tarifa e FamilySize\n",
    "X = df[['Pclass', 'Sex', 'Age', 'Fare', 'FamilySize']]\n",
    "y = df['Survived']\n",
    "\n",
    "# Dividir os dados (70% treino, 30% teste) com estratificação para manter a proporção de sobreviventes\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
    "\n",
    "print(\"Tamanho do conjunto de treinamento:\", X_train.shape)\n",
    "print(\"Tamanho do conjunto de teste:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9d00ef3",
   "metadata": {},
   "source": [
    "## 4. Treinamento do Modelo de Regressão Logística\n",
    "\n",
    "Agora, treinamos o modelo de regressão logística utilizando os dados de treinamento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4fcd0a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Instanciar o modelo de Regressão Logística (definindo max_iter para garantir convergência)\n",
    "modelo = LogisticRegression(max_iter=200)\n",
    "\n",
    "# Treinar o modelo com os dados de treinamento\n",
    "modelo.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ed2d2a0",
   "metadata": {},
   "source": [
    "## 5. Exibição e Interpretação dos Coeficientes\n",
    "\n",
    "Após o treinamento, exibimos os coeficientes (pesos) do modelo, que indicam o impacto de cada variável preditora na probabilidade de sobrevivência."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb38c35a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exibir os coeficientes (pesos) do modelo\n",
    "print(\"Pesos (coeficientes):\", modelo.coef_)\n",
    "\n",
    "# Exibir o intercepto\n",
    "print(\"Intercepto:\", modelo.intercept_)\n",
    "\n",
    "# Exibir os coeficientes de forma organizada, associando cada feature ao seu respectivo peso\n",
    "features = X.columns\n",
    "for feature, coef in zip(features, modelo.coef_[0]):\n",
    "    print(f\"{feature}: {coef}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e4fa7b5",
   "metadata": {},
   "source": [
    "## 6. Geração das Curvas de Análise de Erro\n",
    "\n",
    "Nesta etapa, geramos diversas curvas para analisar o desempenho do modelo no conjunto de teste:\n",
    "\n",
    "- **Curva ROC:** Taxa de Verdadeiro Positivo (TPR) vs. Taxa de Falso Positivo (FPR).\n",
    "- **Curva Precision-Recall:** Relação entre Precisão e Recall.\n",
    "- **Curva de Erro vs. Threshold:** Variação da taxa de erro para diferentes thresholds.\n",
    "- **Curva de Calibração (Opcional):** Comparação entre probabilidades previstas e probabilidades reais."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0550f61e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, roc_auc_score, precision_recall_curve, average_precision_score\n",
    "from sklearn.calibration import calibration_curve\n",
    "\n",
    "# Obter as probabilidades preditas para a classe positiva\n",
    "y_prob = modelo.predict_proba(X_test)[:, 1]\n",
    "\n",
    "## 6.1. Curva ROC\n",
    "\n",
    "fpr, tpr, thresholds_roc = roc_curve(y_test, y_prob)\n",
    "auc_value = roc_auc_score(y_test, y_prob)\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.plot(fpr, tpr, label=f\"Curva ROC (AUC = {auc_value:.2f})\")\n",
    "plt.plot([0, 1], [0, 1], 'k--', label=\"Linha de referência\")\n",
    "plt.xlabel(\"Taxa de Falso Positivo (FPR)\")\n",
    "plt.ylabel(\"Taxa de Verdadeiro Positivo (TPR)\")\n",
    "plt.title(\"Curva ROC\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "## 6.2. Curva Precision-Recall\n",
    "\n",
    "precision, recall, thresholds_pr = precision_recall_curve(y_test, y_prob)\n",
    "avg_precision = average_precision_score(y_test, y_prob)\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.plot(recall, precision, label=f\"Curva Precision-Recall (AP = {avg_precision:.2f})\")\n",
    "plt.xlabel(\"Recall\")\n",
    "plt.ylabel(\"Precisão\")\n",
    "plt.title(\"Curva Precision-Recall\")\n",
    "plt.legend(loc=\"lower left\")\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "## 6.3. Curva de Erro vs. Threshold\n",
    "\n",
    "thresholds = np.linspace(0, 1, 100)\n",
    "error_rates = []\n",
    "\n",
    "for thresh in thresholds:\n",
    "    y_pred_thresh = (y_prob >= thresh).astype(int)\n",
    "    error_rate = np.mean(y_pred_thresh != y_test)\n",
    "    error_rates.append(error_rate)\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.plot(thresholds, error_rates, label=\"Taxa de Erro\")\n",
    "plt.xlabel(\"Threshold\")\n",
    "plt.ylabel(\"Taxa de Erro\")\n",
    "plt.title(\"Curva de Erro vs. Threshold\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "## 6.4. Curva de Calibração (Opcional)\n",
    "\n",
    "prob_true, prob_pred = calibration_curve(y_test, y_prob, n_bins=10)\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.plot(prob_pred, prob_true, marker='o', label=\"Curva de Calibração\")\n",
    "plt.plot([0, 1], [0, 1], linestyle='--', label=\"Calibração Perfeita\")\n",
    "plt.xlabel(\"Probabilidade Prevista\")\n",
    "plt.ylabel(\"Probabilidade Real (em cada bin)\")\n",
    "plt.title(\"Curva de Calibração\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
