{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6d1c12ad-d8f5-4e4a-9c37-6c0ecfdac3ec",
   "metadata": {},
   "source": [
    "# Modelo Preditivo com Regressão Logística - Dataset Titanic\n",
    "\n",
    "Neste notebook, vamos construir um modelo de regressão logística utilizando o dataset do Titanic. \n",
    "\n",
    "Arquivos utilizados:\n",
    "- **train.csv**: Dataset de treino (contém a coluna `Survived`).\n",
    "- **test.csv**: Dataset de teste (não contém `Survived`).\n",
    "- **gender_submission.csv**: Arquivo que contém os rótulos reais para os dados de teste, no formato: `PassengerId, Survived`.\n",
    "\n",
    "O fluxo do notebook será:\n",
    "\n",
    "1. Pré-processamento dos dados de treino e teste\n",
    "2. Criação de features (incluindo one-hot encoding para variáveis categóricas)\n",
    "3. Treinamento do modelo com `train.csv`\n",
    "4. Geração de predições para `test.csv`\n",
    "5. Avaliação das predições comparando com o arquivo `gender_submission.csv`\n",
    "\n",
    "Vamos começar!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c788d6f1-41e2-4538-a5a2-8832a583e8f6",
   "metadata": {},
   "source": [
    "## 1. Carregamento dos Dados\n",
    "\n",
    "Carregamos os arquivos de treino, teste e submissão."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb0b8e0b-ced2-4316-a4a8-588cbf30d47a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Carregar o dataset de treino (contém 'Survived')\n",
    "train_df = pd.read_csv('train.csv')\n",
    "\n",
    "# Carregar o dataset de teste (não contém 'Survived')\n",
    "test_df = pd.read_csv('test.csv')\n",
    "\n",
    "# Carregar o arquivo de submissão (rótulos verdadeiros para o teste)\n",
    "submission_true = pd.read_csv('gender_submission.csv')\n",
    "\n",
    "print('Treino:', train_df.shape)\n",
    "print('Teste:', test_df.shape)\n",
    "print('Submission:', submission_true.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82f53e8a-5e60-40d5-99b9-79a7fbe4d1fa",
   "metadata": {},
   "source": [
    "## 2. Pré-processamento dos Dados\n",
    "\n",
    "Nesta etapa, vamos tratar valores ausentes, remover colunas irrelevantes e converter variáveis categóricas para formato numérico. \n",
    "\n",
    "### 2.1 Pré-processamento do dataset de treino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e917e3e-4a68-4f6c-b1b0-27ce12e2a2c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preencher valores ausentes na coluna 'Age' com a mediana\n",
    "train_df['Age'].fillna(train_df['Age'].median(), inplace=True)\n",
    "\n",
    "# Preencher valores ausentes na coluna 'Embarked' com a moda\n",
    "train_df['Embarked'].fillna(train_df['Embarked'].mode()[0], inplace=True)\n",
    "\n",
    "# Remover colunas que não serão utilizadas: 'Cabin', 'Ticket', 'Name'\n",
    "train_df.drop(['Cabin', 'Ticket', 'Name'], axis=1, inplace=True)\n",
    "\n",
    "# Converter a coluna 'Sex' para numérico: male -> 1, female -> 0\n",
    "train_df['Sex'] = train_df['Sex'].map({'male': 1, 'female': 0})\n",
    "\n",
    "# Criar a feature 'FamilySize' (número de familiares a bordo)\n",
    "train_df['FamilySize'] = train_df['SibSp'] + train_df['Parch']\n",
    "\n",
    "# Aplicar one-hot encoding para a coluna 'Embarked'\n",
    "train_df = pd.get_dummies(train_df, columns=['Embarked'], drop_first=True)\n",
    "\n",
    "print(train_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caac7d79-0a56-4d79-8a26-70dbfae48c9c",
   "metadata": {},
   "source": [
    "### 2.2 Pré-processamento do dataset de teste\n",
    "\n",
    "Realizamos os mesmos passos de pré-processamento no dataset de teste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "406fa953-191f-4c8e-8a29-d2b7c1a0e16a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preencher valores ausentes na coluna 'Age' com a mediana\n",
    "test_df['Age'].fillna(test_df['Age'].median(), inplace=True)\n",
    "\n",
    "# Preencher valores ausentes na coluna 'Fare' (caso existam) com a mediana\n",
    "test_df['Fare'].fillna(test_df['Fare'].median(), inplace=True)\n",
    "\n",
    "# Preencher valores ausentes na coluna 'Embarked' com a moda\n",
    "test_df['Embarked'].fillna(test_df['Embarked'].mode()[0], inplace=True)\n",
    "\n",
    "# Remover colunas: 'Cabin', 'Ticket', 'Name'\n",
    "test_df.drop(['Cabin', 'Ticket', 'Name'], axis=1, inplace=True)\n",
    "\n",
    "# Converter a coluna 'Sex' para numérico\n",
    "test_df['Sex'] = test_df['Sex'].map({'male': 1, 'female': 0})\n",
    "\n",
    "# Criar a feature 'FamilySize'\n",
    "test_df['FamilySize'] = test_df['SibSp'] + test_df['Parch']\n",
    "\n",
    "# Aplicar one-hot encoding para a coluna 'Embarked'\n",
    "test_df = pd.get_dummies(test_df, columns=['Embarked'], drop_first=True)\n",
    "\n",
    "print(test_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10a2fbb3-3305-4d07-bf59-dbe1c7e9736c",
   "metadata": {},
   "source": [
    "## 3. Treinamento do Modelo\n",
    "\n",
    "Utilizaremos o dataset de treino para ajustar um modelo de regressão logística.\n",
    "\n",
    "Como a coluna `PassengerId` não é uma feature útil, vamos removê-la. O mesmo vale para a variável target que está em `Survived`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d13b42a-6dbe-4f25-a1c8-78f7e2bb88ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparar os dados de treino removendo 'PassengerId' e separando a variável target\n",
    "X_train = train_df.drop(['PassengerId', 'Survived'], axis=1)\n",
    "y_train = train_df['Survived']\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Instanciar e treinar o modelo\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "print(\"Modelo treinado com sucesso!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d4fa5d3-1d86-4f77-b6f2-5b3de9a7ed41",
   "metadata": {},
   "source": [
    "## 4. Geração de Predições e Criação do Arquivo de Submissão\n",
    "\n",
    "Vamos usar o modelo treinado para gerar predições no dataset de teste e, em seguida, criar um arquivo de submissão. \n",
    "\n",
    "Obs.: Removemos a coluna `PassengerId` do conjunto de teste para predição, mas ela será incluída no arquivo final."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89cb0b34-fdd0-42a5-990b-81c6c934cc8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparar os dados de teste removendo a coluna 'PassengerId' (somente para predição)\n",
    "X_test = test_df.drop('PassengerId', axis=1)\n",
    "\n",
    "# Gerar as predições para o conjunto de teste\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "# Criar um DataFrame para a submissão\n",
    "submission = pd.DataFrame({\n",
    "    'PassengerId': test_df['PassengerId'],\n",
    "    'Survived': predictions\n",
    "})\n",
    "\n",
    "# Salvar o arquivo de submissão\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "print(\"Arquivo submission.csv gerado com sucesso!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e5e4dd6-cb95-43e2-a08e-19de2f3e3d11",
   "metadata": {},
   "source": [
    "## 5. Avaliação do Modelo (Auto-Avaliação)\n",
    "\n",
    "Para avaliar a acurácia das predições, vamos comparar o arquivo `submission.csv` (nossas predições) com o arquivo `gender_submission.csv`, que contém os rótulos verdadeiros para os dados de teste. \n",
    "\n",
    "Utilizaremos métricas como acurácia, matriz de confusão e relatório de classificação."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff63a245-631f-4f45-9bb4-6d720e5c3748",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "# Carregar o arquivo de submissão verdadeiro (gender_submission.csv)\n",
    "true_submission = pd.read_csv('gender_submission.csv')\n",
    "\n",
    "# Carregar o arquivo gerado pelo modelo\n",
    "pred_submission = pd.read_csv('submission.csv')\n",
    "\n",
    "# Fazer o merge dos dois DataFrames com base em PassengerId\n",
    "merged = pd.merge(true_submission, pred_submission, on='PassengerId', how='inner')\n",
    "\n",
    "# Calcular a acurácia\n",
    "accuracy = accuracy_score(merged['Survived_x'], merged['Survived_y'])\n",
    "print(\"Acurácia das predições:\", accuracy)\n",
    "\n",
    "# Exibir a matriz de confusão\n",
    "cm = confusion_matrix(merged['Survived_x'], merged['Survived_y'])\n",
    "print(\"Matriz de Confusão:\\n\", cm)\n",
    "\n",
    "# Exibir relatório de classificação\n",
    "report = classification_report(merged['Survived_x'], merged['Survived_y'])\n",
    "print(\"Relatório de Classificação:\\n\", report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0169d051-445d-4bd1-945e-4578d68dfe42",
   "metadata": {},
   "source": [
    "## 6. Conclusão\n",
    "\n",
    "Neste notebook, vimos como:\n",
    "\n",
    "- Realizar o pré-processamento dos dados (tratamento de valores ausentes, conversão de variáveis categóricas e criação de novas features).\n",
    "- Treinar um modelo de regressão logística utilizando o dataset de treino.\n",
    "- Gerar predições para o dataset de teste e criar um arquivo de submissão.\n",
    "- Avaliar as predições comparando com os rótulos verdadeiros do arquivo `gender_submission.csv`."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
